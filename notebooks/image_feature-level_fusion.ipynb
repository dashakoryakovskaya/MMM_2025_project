{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be41b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings(\"ignore\", category = warn)\n",
    "\n",
    "# Импорт необходимых библиотек\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel,AutoModelForMaskedLM\n",
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from einops import rearrange\n",
    "from typing import Tuple, Callable\n",
    "from torch.autograd import Function\n",
    "import gc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddacfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['activation_date'] = pd.to_datetime(df['activation_date'])\n",
    "\n",
    "    df['day'] = df['activation_date'].dt.day\n",
    "    df['month'] = df[\"activation_date\"].dt.month\n",
    "    df['year'] = df[\"activation_date\"].dt.year\n",
    "    df['weekday'] = df['activation_date'].dt.weekday\n",
    "    df[\"dayofyear\"] = df['activation_date'].dt.dayofyear\n",
    "    df.drop(columns=['activation_date', 'item_id'], inplace=True)\n",
    "    df['param_1'] = df['param_1'].fillna('')\n",
    "    df['param_2'] = df['param_2'].fillna('')\n",
    "    df['param_3'] = df['param_3'].fillna('')\n",
    "    df['description'] = df['description'].fillna('')\n",
    "    return df\n",
    "\n",
    "#item_id = test.item_id\n",
    "#train = preprocess(train)\n",
    "#test = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b5b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_avito(): \n",
    "    def __init__(self, part='train', path=None, len_1=15034, len_2=15034): \n",
    "        train = pd.read_csv('../data/train.csv')\n",
    "        train_1 = train[train.deal_probability != 0.0].iloc[0:len_1]\n",
    "        train_2 = train[train.deal_probability == 0.0].iloc[0:len_2]\n",
    "        #train = train.iloc[0:15034]\n",
    "        train = pd.concat([train_1, train_2])\n",
    "        train = preprocess(train)\n",
    "        train.loc[:, \"index_col\"] = list(range(len(train)))\n",
    "        train.set_index('index_col', drop=True, append=False, inplace=True)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(train.drop(columns=['deal_probability']), train['deal_probability'], test_size=0.2, random_state=42)\n",
    "        self.x = X_train if part == 'train' else X_val\n",
    "        self.y = y_train if part == 'train' else y_val\n",
    "        self.n_samples = X_train.shape[0] if part == 'train' else X_val.shape[0]\n",
    "        self.text = list(self.x.apply(lambda item: '\\n'.join([ item[\"title\"], str(item[\"description\"]), item[\"region\"], item[\"city\"], item[\"parent_category_name\"], item[\"category_name\"], ('' if item[\"param_1\"] is None else str(item[\"param_1\"])), ('' if item[\"param_2\"] is None else str(item[\"param_2\"])), ('' if item[\"param_3\"] is None else str(item[\"param_3\"]))]), axis=1).values)\n",
    "        user_type_dict = {'Private': 0, 'Company': 1, 'Shop': 2}\n",
    "        self.tabular = list(self.x.apply(lambda item: torch.tensor([item[\"item_seq_number\"], item[\"day\"], item[\"month\"], item[\"year\"], item[\"weekday\"], item[\"dayofyear\"], user_type_dict[item[\"user_type\"]], 0.0 if item[\"price\"] is None else item[\"price\"]]), axis=1).values)\n",
    "        #self.image = list(self.x.image.apply(lambda x : 'nan' if str(x) == 'nan' else x).values)\n",
    "        self.image = list(self.x.index.values)\n",
    "        \n",
    "        if path is not None:\n",
    "            index = list(self.x.index.values)\n",
    "            with open(path, 'rb') as f:\n",
    "                self.text_embedding_all = pickle.load(f)\n",
    "            self.text_embedding = []\n",
    "            for i in index:\n",
    "                try:\n",
    "                    self.text_embedding.append(self.text_embedding_all[i])\n",
    "                except:\n",
    "                    print(i)\n",
    "                \n",
    "        else:\n",
    "            self.text_embedding = []\n",
    "            for t in tqdm(self.text):\n",
    "                encoded_input = feature_extractor_tokenizer(t, padding=True, truncation=True, return_tensors='pt').to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    features = feature_extractor_model(**encoded_input)[0][0]\n",
    "                self.text_embedding.append(features)\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        return self.tabular[index], self.text[index], self.text_embedding[index], self.image[index], np.array(self.y)[index] \n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593e287b-f91a-4767-bab8-d428827ad892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch = [x for x in batch if x is not None]\n",
    "    if not batch:\n",
    "        return None\n",
    "    \n",
    "\n",
    "    return [\n",
    "        [torch.tensor(b[0]) for b in batch],\n",
    "        [b[1] for b in batch],\n",
    "        [torch.tensor(b[2]) for b in batch],\n",
    "        [b[3] for b in batch],\n",
    "        [torch.tensor(b[4]) for b in batch],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a6a6a2-8b07-4c6e-8aa9-2430fb639b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset=Dataset_avito('train', path='train_text_features'), batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(dataset=Dataset_avito('val', path='train_text_features'), batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3233d47f-0895-4c72-8202-8b906b14b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "image_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416cb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import ClassVar\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "@dataclass\n",
    "class ModelTrainer:\n",
    "    model: 'typing.Any'\n",
    "    train_dataloader: DataLoader\n",
    "    val_dataloader: DataLoader\n",
    "    device: torch.device\n",
    "    epochs: int\n",
    "    round_loss: int\n",
    "    round_rmse: int\n",
    "\n",
    "    optimizer: torch.optim\n",
    "    loss_fn: 'typing.Any'\n",
    "    \n",
    "    patience: int = 10 # Ранняя остановка обучения\n",
    "    \n",
    "    random_seed: int = 0\n",
    "\n",
    "    def __post_init__(self):        \n",
    "        # История обучения и тестирования\n",
    "        self.__history = pd.DataFrame({\n",
    "            \"train_avg\": [], # Средние метрики на тренировочной выборке\n",
    "            \"val_avg\": [], # Средние метрики на валидационной выборке\n",
    "            \"train_loss\": [], # Loss на тренировочной выборке\n",
    "            \"val_loss\": [], # Loss на валидационной выборке\n",
    "        })\n",
    "\n",
    "        # Количество шагов в одной эпохе\n",
    "        self.__train_steps = len(self.train_dataloader)\n",
    "        self.__val_steps = len(self.val_dataloader)\n",
    "\n",
    "        self.__best_val_avg = 0\n",
    "        self.__no_improvement_count = 0\n",
    "        \n",
    "        self.loss_fn = self.loss_fn\n",
    "        \n",
    "        if self.random_seed > 0:\n",
    "            random.seed(self.random_seed)\n",
    "            torch.manual_seed(self.random_seed)\n",
    "            torch.cuda.manual_seed_all(self.random_seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "            os.environ['PYTHONHASHSEED'] = str(self.random_seed)\n",
    "            generator = torch.Generator()\n",
    "            generator.manual_seed(self.random_seed)\n",
    "\n",
    "    @property\n",
    "    def history(self) -> pd.DataFrame:\n",
    "        \"\"\"Получение DataFrame историей обучения и тестирования\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: **DataFrame** c историей обучения и тестирования\n",
    "        \"\"\"\n",
    "\n",
    "        return self.__history\n",
    "\n",
    "    @classmethod\n",
    "    def _is_best_model(self, dev_avg: float) -> bool:\n",
    "        \"\"\"Проверка, является ли текущая модель лучшей на основе метрик валидации\n",
    "\n",
    "        Args:\n",
    "            test_accuracy (float): Текущая точность тестирования\n",
    "\n",
    "        Returns:\n",
    "            bool: True, если текущая модель лучшая, иначе False\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            min_val_avg = min(self.__history[\"val_avg\"])\n",
    "        except ValueError:\n",
    "            min_val_avg = 10**10\n",
    "        return dev_avg < min_val_avg\n",
    "\n",
    "    def _save_model(self, epoch: int, path_to_model: str, test_rmse: float, loss: torch.Tensor) -> None:\n",
    "        \"\"\"Сохранение модели\n",
    "\n",
    "        Args:\n",
    "            epoch (int): Текущая эпоха\n",
    "            path_to_model (str): Путь для сохранения модели\n",
    "            test_rmse (float): rmse на тестовой выборке\n",
    "            loss (torch.Tensor): Значение потерь\n",
    "        \"\"\"\n",
    "        \n",
    "        os.makedirs(path_to_model, exist_ok = True)\n",
    "        self._best_model_name = f\"{self.model.__class__.__name__}_{epoch}_{test_rmse}_checkpoint.pth\"\n",
    "\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"test_loss\": loss,\n",
    "        }, os.path.join(path_to_model, f\"{self.model.__class__.__name__}_{epoch}_{test_rmse}_checkpoint.pth\"))\n",
    "    \n",
    "    # Процесс обучения\n",
    "    def train(self, path_to_model: str) -> None:\n",
    "        \"\"\"Процесс обучения\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): Путь для сохранения моделей\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        losses_train_list = []\n",
    "        losses_val_list = []\n",
    "        rmse_train_list = []\n",
    "        rmse_val_list = []\n",
    "        min_val_rmse = 10**10\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            with torch.no_grad():\n",
    "                torch.cuda.empty_cache()\n",
    "            self.model.train() # Установка модели в режим обучения\n",
    "            # Сумма Loss\n",
    "            total_train_loss = 0\n",
    "            total_val_loss = 0\n",
    "            # Сумма rmse\n",
    "            train_rmse = 0\n",
    "            val_rmse = 0\n",
    "\n",
    "            # Проход по всем тренировочным пакетам\n",
    "            with tqdm(total = self.__train_steps, desc = f\"Эпоха {epoch}\", unit = \"batch\") as pbar_train:\n",
    "                for batch, (tabular, text, text_embedding, images, targets) in enumerate(self.train_dataloader, 1):\n",
    "                    # tabular\n",
    "                    tabular = torch.stack(tabular).unsqueeze(2).expand(-1, -1, 1024).to(device)\n",
    "                    tabular = torch.nan_to_num(tabular,nan=0.0)\n",
    "                    tabular = F.normalize(tabular, dim=1, eps=1e-6)\n",
    "                    # text\n",
    "                    text_embedding = torch.nn.utils.rnn.pad_sequence(text_embedding, batch_first=True)\n",
    "                    text_embedding = text_embedding.to(device)\n",
    "                    # image\n",
    "                    image_embedding = []\n",
    "                    for i in range(len(images)):\n",
    "                        with open(\"../data/vit_train_jpg/\" + str(images[i]), 'rb') as f:\n",
    "                            x = pickle.load(f)\n",
    "                        image_embedding.append(x.squeeze(dim=0))\n",
    "                    image_embedding = torch.nn.utils.rnn.pad_sequence(image_embedding, batch_first=True)\n",
    "                    image_embedding = image_embedding.to(device)\n",
    "                    image_embedding = image_embedding.squeeze(dim=1)\n",
    "\n",
    "                    image_embedding = F.pad(image_embedding, (0, 1024-768), \"constant\", 0)\n",
    "                    \n",
    "                    \n",
    "                    emb_concat = torch.concat((tabular.to(device), text_embedding.to(device), image_embedding.to(device)), dim=1)\n",
    "                    emb_concat = emb_concat.to(device)\n",
    "\n",
    "                    targets = torch.stack(targets)\n",
    "                    targets = targets.to(device)\n",
    "                    logits = self.model(emb_concat)\n",
    "                    #logits = torch.nan_to_num(logits, nan=0.0)\n",
    "                    loss = self.loss_fn(logits, targets.float()) # Ошибка предсказаний\n",
    "\n",
    "                    # Обратное распространение для обновления весов\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                    self.optimizer.step()\n",
    "        \n",
    "                    total_train_loss += loss.item() # Потеря\n",
    "                    # RMSE\n",
    "                    train_rmse += root_mean_squared_error(targets.cpu().detach().numpy(), logits.cpu().detach().numpy())\n",
    "        \n",
    "                    pbar_train.update(1)\n",
    "                    with torch.no_grad():\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                # Средняя потеря\n",
    "                avg_train_loss = round(total_train_loss / batch, self.round_loss)\n",
    "                losses_train_list.append(avg_train_loss)\n",
    "        \n",
    "                # RMSE\n",
    "                train_rmse = round(train_rmse / len(self.train_dataloader.dataset) * 100, self.round_rmse)\n",
    "                rmse_train_list.append(train_rmse)\n",
    "        \n",
    "                pbar_train.set_postfix({\n",
    "                    \"rmse\": train_rmse,\n",
    "                    \"Средняя потеря\": avg_train_loss\n",
    "                })\n",
    "            \n",
    "            \n",
    "            # Установка модели в режим предсказаний\n",
    "            self.model.eval()\n",
    "        \n",
    "            # Предсказания на валидационной выборке\n",
    "            with torch.no_grad():\n",
    "                with tqdm(total = self.__val_steps, desc = f\"Тестирование {epoch}\", unit = \"batch\") as pbar_val:\n",
    "                    for batch, (tabular, text, text_embedding, images, targets) in enumerate(self.val_dataloader, 1):\n",
    "                        # tabular\n",
    "                        tabular = torch.stack(tabular).unsqueeze(2).expand(-1, -1, 1024).to(device)\n",
    "                        tabular = torch.nan_to_num(tabular,nan=0.0)\n",
    "                        tabular = F.normalize(tabular, dim=1, eps=1e-6)\n",
    "                        # text\n",
    "                        text_embedding = torch.nn.utils.rnn.pad_sequence(text_embedding, batch_first=True)\n",
    "                        text_embedding = text_embedding.to(device)\n",
    "                        # image\n",
    "                        image_embedding = []\n",
    "                        for i in range(len(images)):\n",
    "                            with open(\"../data/vit_train_jpg/\" + str(images[i]), 'rb') as f:\n",
    "                                x = pickle.load(f)\n",
    "                            image_embedding.append(x.squeeze(dim=0))\n",
    "                        image_embedding = torch.nn.utils.rnn.pad_sequence(image_embedding, batch_first=True)\n",
    "                        image_embedding = image_embedding.to(device)\n",
    "                        image_embedding = image_embedding.squeeze(dim=1)\n",
    "                        image_embedding = F.pad(image_embedding, (0, 1024-768), \"constant\", 0)\n",
    "                        emb_concat = torch.concat((tabular.to(device), text_embedding.to(device), image_embedding.to(device)), dim=1)\n",
    "                        emb_concat = emb_concat.to(device)\n",
    "                        targets = torch.stack(targets)\n",
    "                        targets = targets.to(device)\n",
    "                        logits = self.model(emb_concat)\n",
    "                        logits = torch.nan_to_num(logits, nan=0.0)\n",
    "                        loss = self.loss_fn(logits, targets.float()) # Ошибка предсказаний\n",
    "                        \n",
    "                        total_val_loss += loss.item() # Потеря\n",
    "                        # RMSE\n",
    "                        val_rmse += root_mean_squared_error(targets.cpu().detach().numpy(), logits.cpu().detach().numpy())\n",
    "        \n",
    "                        pbar_val.update(1)\n",
    "                        with torch.no_grad():\n",
    "                            torch.cuda.empty_cache()\n",
    "                    # Средняя потеря\n",
    "                    avg_val_loss = round(total_val_loss / batch, self.round_loss)\n",
    "                    losses_val_list.append(avg_val_loss)\n",
    "        \n",
    "                    # RMSE\n",
    "                    val_rmse = round(val_rmse / len(self.val_dataloader.dataset) * 100, self.round_rmse)\n",
    "                    rmse_val_list.append(val_rmse)\n",
    "                    \n",
    "                    pbar_val.set_postfix({\n",
    "                        \"rmse\": val_rmse,\n",
    "                        \"Средняя потеря\": avg_val_loss\n",
    "                    })\n",
    "            \n",
    "            if val_rmse < min_val_rmse:\n",
    "                min_val_rmse = val_rmse\n",
    "                self._save_model(epoch, path_to_model, round(val_rmse, self.round_rmse), avg_val_loss)\n",
    "                self.__best_dev_avg = val_rmse\n",
    "                self.__no_improvement_count = 0\n",
    "            else:\n",
    "                self.__no_improvement_count += 1\n",
    "\n",
    "            if self.__no_improvement_count >= self.patience:\n",
    "                print(f\"Ранняя остановка на эпохе {epoch} из-за отсутствия улучшения точности на тестовой выборке\")\n",
    "                return path_to_model\n",
    "\n",
    "    # Получение хэш-значения\n",
    "    def __hash__(self):\n",
    "        return id(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f88a32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20 # Количество эпох\n",
    "BATCH_SIZE = 32 # Размер выборки (пакета)\n",
    "LEARNING_RATE = 1e-4 # Скорость обучения\n",
    "ROUND_RMSE = 2 # Знаков Accuracy после запятой\n",
    "ROUND_LOSS = 7 # Знаков Loss после запятой\n",
    "ROOT_DIR = os.path.join(\".\")\n",
    "PATH_TO_MODEL = os.path.join(ROOT_DIR, \"Models_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31379769-0352-474f-adea-65d8843cea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v3\", code_revision='da863dd04a4e5dce6814c6625adfba87b83838aa', trust_remote_code=True)\n",
    "feature_extractor_model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", code_revision='da863dd04a4e5dce6814c6625adfba87b83838aa', trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e16403ad-2eb6-473f-9320-597435e6e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer_2 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = F.gelu(x)  # Более плавная активация\n",
    "        x = self.dropout(x)\n",
    "        return self.layer_2(x)\n",
    "\n",
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        return self.norm(x + self.dropout(residual))\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(1)].detach()  # Отключаем градиенты\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dropout=0.1, positional_encoding=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.self_attention = nn.MultiheadAttention(input_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.feed_forward = PositionWiseFeedForward(input_dim, input_dim, dropout=dropout)\n",
    "        self.add_norm_after_attention = AddAndNorm(input_dim, dropout=dropout)\n",
    "        self.add_norm_after_ff = AddAndNorm(input_dim, dropout=dropout)\n",
    "        self.positional_encoding = PositionalEncoding(input_dim) if positional_encoding else None\n",
    "\n",
    "    def forward(self, key, value, query):\n",
    "        if self.positional_encoding:\n",
    "            key = self.positional_encoding(key)\n",
    "            value = self.positional_encoding(value)\n",
    "            query = self.positional_encoding(query)\n",
    "\n",
    "        attn_output, _ = self.self_attention(query, key, value, need_weights=False)\n",
    "\n",
    "        x = self.add_norm_after_attention(attn_output, query)\n",
    "\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.add_norm_after_ff(ff_output, x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aad5e68-3117-4b17-92da-548d34007112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModelWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim = 1024, hidden_dim=128, num_heads = 4, num_layers = 8, dropout = 0.1, positional_encoding=True):\n",
    "        super(TransformerModelWithAttention, self).__init__()\n",
    "        self.in_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.positional_encoding = PositionalEncoding(hidden_dim)\n",
    "        self.transformer_encoder = nn.ModuleList([TransformerEncoderLayer(input_dim=hidden_dim, num_heads=num_heads, positional_encoding=positional_encoding, dropout=dropout) for i in range(num_layers)])\n",
    "        self.fc_out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = self.in_layer(x)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        x = self.positional_encoding(x)\n",
    "        for i in range(len(self.transformer_encoder)):\n",
    "            x = x + self.transformer_encoder[i](x, x, x)\n",
    "        x = x.mean(dim = 1)\n",
    "        return self.fc_out(x).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c3fe71d6-7c1a-4d59-8b17-101d4c7f546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 100%|██████████| 376/376 [05:59<00:00,  1.04batch/s, rmse=0.93, Средняя потеря=0.0918]\n",
      "Тестирование 1: 100%|██████████| 94/94 [01:41<00:00,  1.07s/batch, rmse=0.93, Средняя потеря=0.0905]\n",
      "Эпоха 2: 100%|██████████| 376/376 [01:43<00:00,  3.64batch/s, rmse=0.86, Средняя потеря=0.0776]\n",
      "Тестирование 2: 100%|██████████| 94/94 [00:18<00:00,  5.00batch/s, rmse=0.86, Средняя потеря=0.0776]\n",
      "Эпоха 3: 100%|██████████| 376/376 [01:41<00:00,  3.69batch/s, rmse=0.84, Средняя потеря=0.0729]\n",
      "Тестирование 3: 100%|██████████| 94/94 [00:22<00:00,  4.18batch/s, rmse=0.87, Средняя потеря=0.0796]\n",
      "Эпоха 4: 100%|██████████| 376/376 [01:46<00:00,  3.52batch/s, rmse=0.84, Средняя потеря=0.0729]\n",
      "Тестирование 4: 100%|██████████| 94/94 [00:19<00:00,  4.72batch/s, rmse=0.84, Средняя потеря=0.0751]\n",
      "Эпоха 5: 100%|██████████| 376/376 [01:47<00:00,  3.50batch/s, rmse=0.83, Средняя потеря=0.0713]\n",
      "Тестирование 5: 100%|██████████| 94/94 [00:21<00:00,  4.29batch/s, rmse=0.86, Средняя потеря=0.0789]\n",
      "Эпоха 6: 100%|██████████| 376/376 [01:55<00:00,  3.25batch/s, rmse=0.82, Средняя потеря=0.0694]\n",
      "Тестирование 6: 100%|██████████| 94/94 [00:20<00:00,  4.69batch/s, rmse=0.85, Средняя потеря=0.0768]\n",
      "Эпоха 7: 100%|██████████| 376/376 [01:49<00:00,  3.43batch/s, rmse=0.81, Средняя потеря=0.0688]\n",
      "Тестирование 7: 100%|██████████| 94/94 [00:22<00:00,  4.21batch/s, rmse=0.85, Средняя потеря=0.0767]\n",
      "Эпоха 8: 100%|██████████| 376/376 [01:53<00:00,  3.30batch/s, rmse=0.81, Средняя потеря=0.0686]\n",
      "Тестирование 8: 100%|██████████| 94/94 [00:23<00:00,  3.94batch/s, rmse=0.87, Средняя потеря=0.0793]\n",
      "Эпоха 9: 100%|██████████| 376/376 [02:01<00:00,  3.11batch/s, rmse=0.81, Средняя потеря=0.0692]\n",
      "Тестирование 9: 100%|██████████| 94/94 [00:22<00:00,  4.12batch/s, rmse=0.85, Средняя потеря=0.0768]\n",
      "Эпоха 10: 100%|██████████| 376/376 [01:58<00:00,  3.17batch/s, rmse=0.8, Средняя потеря=0.0674]\n",
      "Тестирование 10: 100%|██████████| 94/94 [00:22<00:00,  4.12batch/s, rmse=0.85, Средняя потеря=0.0761]\n",
      "Эпоха 11: 100%|██████████| 376/376 [01:58<00:00,  3.17batch/s, rmse=0.8, Средняя потеря=0.0667]\n",
      "Тестирование 11: 100%|██████████| 94/94 [00:24<00:00,  3.88batch/s, rmse=0.86, Средняя потеря=0.0779]\n",
      "Эпоха 12: 100%|██████████| 376/376 [02:00<00:00,  3.11batch/s, rmse=0.79, Средняя потеря=0.0658]\n",
      "Тестирование 12: 100%|██████████| 94/94 [00:23<00:00,  3.95batch/s, rmse=0.86, Средняя потеря=0.0768]\n",
      "Эпоха 13: 100%|██████████| 376/376 [02:00<00:00,  3.13batch/s, rmse=0.79, Средняя потеря=0.0658]\n",
      "Тестирование 13: 100%|██████████| 94/94 [00:22<00:00,  4.09batch/s, rmse=0.85, Средняя потеря=0.0763]\n",
      "Эпоха 14: 100%|██████████| 376/376 [01:57<00:00,  3.20batch/s, rmse=0.79, Средняя потеря=0.0653]\n",
      "Тестирование 14: 100%|██████████| 94/94 [00:24<00:00,  3.85batch/s, rmse=0.87, Средняя потеря=0.0789]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе 14 из-за отсутствия улучшения точности на тестовой выборке\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./Models_transformer'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer = TransformerModelWithAttention(num_layers=2, input_dim=1024, hidden_dim=128, num_heads=2).to(device)\n",
    "optimizer = optim.Adam(params = model_transformer.parameters(), lr = LEARNING_RATE)\n",
    "loss_fn = nn.MSELoss()\n",
    "trainer = ModelTrainer(model_transformer, train_dataloader, val_dataloader, device, EPOCHS, ROUND_LOSS, ROUND_RMSE, optimizer, loss_fn, random_seed=42)\n",
    "trainer.train(PATH_TO_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55574c53-1926-49ee-a501-e1d4a0b16941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 100%|██████████| 752/752 [09:16<00:00,  1.35batch/s, rmse=0.91, Средняя потеря=0.0857]\n",
      "Тестирование 1: 100%|██████████| 188/188 [02:25<00:00,  1.29batch/s, rmse=0.87, Средняя потеря=0.0791]\n",
      "Эпоха 2: 100%|██████████| 752/752 [03:09<00:00,  3.96batch/s, rmse=0.87, Средняя потеря=0.0783]\n",
      "Тестирование 2: 100%|██████████| 188/188 [00:38<00:00,  4.90batch/s, rmse=0.87, Средняя потеря=0.0794]\n",
      "Эпоха 3: 100%|██████████| 752/752 [03:11<00:00,  3.93batch/s, rmse=0.85, Средняя потеря=0.0747]\n",
      "Тестирование 3: 100%|██████████| 188/188 [00:37<00:00,  4.95batch/s, rmse=0.93, Средняя потеря=0.0904]\n",
      "Эпоха 4: 100%|██████████| 752/752 [03:09<00:00,  3.97batch/s, rmse=0.83, Средняя потеря=0.0722]\n",
      "Тестирование 4: 100%|██████████| 188/188 [00:38<00:00,  4.87batch/s, rmse=0.94, Средняя потеря=0.0923]\n",
      "Эпоха 5: 100%|██████████| 752/752 [03:10<00:00,  3.95batch/s, rmse=0.82, Средняя потеря=0.0709]\n",
      "Тестирование 5: 100%|██████████| 188/188 [00:38<00:00,  4.89batch/s, rmse=0.85, Средняя потеря=0.0748]\n",
      "Эпоха 6: 100%|██████████| 752/752 [03:11<00:00,  3.92batch/s, rmse=0.82, Средняя потеря=0.0706]\n",
      "Тестирование 6: 100%|██████████| 188/188 [00:38<00:00,  4.90batch/s, rmse=0.84, Средняя потеря=0.0747]\n",
      "Эпоха 7: 100%|██████████| 752/752 [03:11<00:00,  3.93batch/s, rmse=0.82, Средняя потеря=0.07]\n",
      "Тестирование 7: 100%|██████████| 188/188 [00:37<00:00,  4.95batch/s, rmse=0.89, Средняя потеря=0.0831]\n",
      "Эпоха 8: 100%|██████████| 752/752 [03:12<00:00,  3.91batch/s, rmse=0.81, Средняя потеря=0.0683]\n",
      "Тестирование 8: 100%|██████████| 188/188 [00:37<00:00,  4.95batch/s, rmse=0.88, Средняя потеря=0.0811]\n",
      "Эпоха 9: 100%|██████████| 752/752 [03:13<00:00,  3.89batch/s, rmse=0.8, Средняя потеря=0.0677]\n",
      "Тестирование 9: 100%|██████████| 188/188 [00:38<00:00,  4.90batch/s, rmse=0.84, Средняя потеря=0.0733]\n",
      "Эпоха 10: 100%|██████████| 752/752 [03:12<00:00,  3.91batch/s, rmse=0.8, Средняя потеря=0.067]\n",
      "Тестирование 10: 100%|██████████| 188/188 [00:38<00:00,  4.90batch/s, rmse=0.89, Средняя потеря=0.0823]\n",
      "Эпоха 11: 100%|██████████| 752/752 [03:11<00:00,  3.92batch/s, rmse=0.8, Средняя потеря=0.0664]\n",
      "Тестирование 11: 100%|██████████| 188/188 [00:38<00:00,  4.93batch/s, rmse=0.89, Средняя потеря=0.0816]\n",
      "Эпоха 12: 100%|██████████| 752/752 [03:20<00:00,  3.76batch/s, rmse=0.79, Средняя потеря=0.0652]\n",
      "Тестирование 12: 100%|██████████| 188/188 [00:39<00:00,  4.73batch/s, rmse=0.87, Средняя потеря=0.0786]\n",
      "Эпоха 13: 100%|██████████| 752/752 [03:16<00:00,  3.83batch/s, rmse=0.78, Средняя потеря=0.0643]\n",
      "Тестирование 13: 100%|██████████| 188/188 [00:38<00:00,  4.91batch/s, rmse=0.92, Средняя потеря=0.0878]\n",
      "Эпоха 14: 100%|██████████| 752/752 [03:17<00:00,  3.80batch/s, rmse=0.78, Средняя потеря=0.0633]\n",
      "Тестирование 14: 100%|██████████| 188/188 [00:37<00:00,  4.95batch/s, rmse=0.92, Средняя потеря=0.0885]\n",
      "Эпоха 15: 100%|██████████| 752/752 [03:16<00:00,  3.83batch/s, rmse=0.77, Средняя потеря=0.0626]\n",
      "Тестирование 15: 100%|██████████| 188/188 [00:39<00:00,  4.72batch/s, rmse=1, Средняя потеря=0.105]\n",
      "Эпоха 16: 100%|██████████| 752/752 [03:19<00:00,  3.76batch/s, rmse=0.76, Средняя потеря=0.0613]\n",
      "Тестирование 16: 100%|██████████| 188/188 [00:39<00:00,  4.77batch/s, rmse=0.92, Средняя потеря=0.0881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе 16 из-за отсутствия улучшения точности на тестовой выборке\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./Models_transformer'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer = TransformerModelWithAttention(num_layers=2, input_dim=1024, hidden_dim=128, num_heads=2).to(device)\n",
    "optimizer = optim.Adam(params = model_transformer.parameters(), lr = LEARNING_RATE)\n",
    "loss_fn = nn.MSELoss()\n",
    "trainer = ModelTrainer(model_transformer, train_dataloader, val_dataloader, device, EPOCHS, ROUND_LOSS, ROUND_RMSE, optimizer, loss_fn, random_seed=42)\n",
    "trainer.train(PATH_TO_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf89cb-984e-4b7d-9707-586a34830c89",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6c322d5-a49c-4bcb-8e62-a67de0e0abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size = 1024, hidden_size = 64, num_layers = 2, dropout = 0.1, bidirectional=True):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = dropout,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(2 * hidden_size, 1)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.lstm.bidirectional:\n",
    "            h0, c0 = torch.zeros(2 * self.num_layers, len(x), self.hidden_size).to(device), torch.zeros(2 * self.num_layers, len(x), self.hidden_size).to(device)\n",
    "        else:\n",
    "            h0, c0 = torch.zeros(self.num_layers, len(x), self.hidden_size).to(device), torch.zeros(self.num_layers, len(x), self.hidden_size).to(device)\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        if self.lstm.bidirectional:\n",
    "            out = torch.cat((hn[-2, :, :], hn[-1, :, :]), dim=1)\n",
    "        else:\n",
    "            out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72df8784-a3ec-4fb5-9ddc-b665148f9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = os.path.join(ROOT_DIR, \"Models_lstm_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216ba66b-a353-478c-8907-9fff54b9256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 100%|██████████| 376/376 [14:20<00:00,  2.29s/batch, rmse=0.91, Средняя потеря=0.0856]\n",
      "Тестирование 1: 100%|██████████| 94/94 [02:26<00:00,  1.56s/batch, rmse=0.89, Средняя потеря=0.0831]\n",
      "Эпоха 4: 100%|██████████| 376/376 [14:23<00:00,  2.30s/batch, rmse=0.9, Средняя потеря=0.0852]\n",
      "Тестирование 4: 100%|██████████| 94/94 [02:25<00:00,  1.55s/batch, rmse=0.89, Средняя потеря=0.0833]\n",
      "Эпоха 6: 100%|██████████| 376/376 [14:20<00:00,  2.29s/batch, rmse=0.9, Средняя потеря=0.0853]\n",
      "Тестирование 6: 100%|██████████| 94/94 [02:26<00:00,  1.56s/batch, rmse=0.89, Средняя потеря=0.0833]\n",
      "Эпоха 8: 100%|██████████| 376/376 [14:20<00:00,  2.29s/batch, rmse=0.9, Средняя потеря=0.0852]\n",
      "Тестирование 8: 100%|██████████| 94/94 [02:26<00:00,  1.55s/batch, rmse=0.89, Средняя потеря=0.083]\n",
      "Эпоха 9: 100%|██████████| 376/376 [14:20<00:00,  2.29s/batch, rmse=0.9, Средняя потеря=0.0852]\n",
      "Тестирование 9: 100%|██████████| 94/94 [02:25<00:00,  1.55s/batch, rmse=0.89, Средняя потеря=0.083]\n",
      "Эпоха 11: 100%|██████████| 376/376 [14:22<00:00,  2.29s/batch, rmse=0.9, Средняя потеря=0.0851]\n",
      "Тестирование 11: 100%|██████████| 94/94 [02:26<00:00,  1.56s/batch, rmse=0.89, Средняя потеря=0.0838]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе 11 из-за отсутствия улучшения точности на тестовой выборке\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_lstm = LSTM().to(device)\n",
    "optimizer = optim.Adam(params = model_lstm.parameters(), lr = LEARNING_RATE)\n",
    "loss_fn = nn.MSELoss()\n",
    "trainer = ModelTrainer(model_lstm, train_dataloader, val_dataloader, device, EPOCHS, ROUND_LOSS, ROUND_RMSE, optimizer, loss_fn)\n",
    "trainer.train(PATH_TO_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "70930c1e-4eff-4621-ad62-82dc76785c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 100%|██████████| 376/376 [01:48<00:00,  3.45batch/s, rmse=0.91, Средняя потеря=0.0864]\n",
      "Тестирование 1: 100%|██████████| 94/94 [00:11<00:00,  8.35batch/s, rmse=0.88, Средняя потеря=0.0835]\n",
      "Эпоха 2: 100%|██████████| 376/376 [00:56<00:00,  6.67batch/s, rmse=0.9, Средняя потеря=0.0853]\n",
      "Тестирование 2: 100%|██████████| 94/94 [00:08<00:00, 10.46batch/s, rmse=0.88, Средняя потеря=0.0833]\n",
      "Эпоха 3: 100%|██████████| 376/376 [00:52<00:00,  7.18batch/s, rmse=0.9, Средняя потеря=0.0852]\n",
      "Тестирование 3: 100%|██████████| 94/94 [00:10<00:00,  9.06batch/s, rmse=0.89, Средняя потеря=0.0832]\n",
      "Эпоха 4: 100%|██████████| 376/376 [00:55<00:00,  6.72batch/s, rmse=0.9, Средняя потеря=0.0851]\n",
      "Тестирование 4: 100%|██████████| 94/94 [00:10<00:00,  9.24batch/s, rmse=0.89, Средняя потеря=0.0831]\n",
      "Эпоха 5: 100%|██████████| 376/376 [00:55<00:00,  6.76batch/s, rmse=0.9, Средняя потеря=0.0852]\n",
      "Тестирование 5: 100%|██████████| 94/94 [00:11<00:00,  8.47batch/s, rmse=0.88, Средняя потеря=0.0831]\n",
      "Эпоха 6: 100%|██████████| 376/376 [00:54<00:00,  6.87batch/s, rmse=0.9, Средняя потеря=0.0851]\n",
      "Тестирование 6: 100%|██████████| 94/94 [00:10<00:00,  8.61batch/s, rmse=0.89, Средняя потеря=0.083]\n",
      "Эпоха 7: 100%|██████████| 376/376 [00:56<00:00,  6.68batch/s, rmse=0.9, Средняя потеря=0.0851]\n",
      "Тестирование 7: 100%|██████████| 94/94 [00:09<00:00,  9.83batch/s, rmse=0.89, Средняя потеря=0.0832]\n",
      "Эпоха 8: 100%|██████████| 376/376 [00:57<00:00,  6.49batch/s, rmse=0.9, Средняя потеря=0.085]\n",
      "Тестирование 8: 100%|██████████| 94/94 [00:10<00:00,  8.69batch/s, rmse=0.89, Средняя потеря=0.0837]\n",
      "Эпоха 9: 100%|██████████| 376/376 [01:33<00:00,  4.04batch/s, rmse=0.9, Средняя потеря=0.085]\n",
      "Тестирование 9: 100%|██████████| 94/94 [00:22<00:00,  4.24batch/s, rmse=0.89, Средняя потеря=0.0831]\n",
      "Эпоха 10: 100%|██████████| 376/376 [01:25<00:00,  4.42batch/s, rmse=0.9, Средняя потеря=0.085]\n",
      "Тестирование 10: 100%|██████████| 94/94 [00:10<00:00,  8.56batch/s, rmse=0.89, Средняя потеря=0.0832]\n",
      "Эпоха 11: 100%|██████████| 376/376 [00:55<00:00,  6.76batch/s, rmse=0.9, Средняя потеря=0.0851]\n",
      "Тестирование 11: 100%|██████████| 94/94 [00:11<00:00,  8.50batch/s, rmse=0.89, Средняя потеря=0.0831]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе 11 из-за отсутствия улучшения точности на тестовой выборке\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./Models_transformer'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm = LSTM().to(device)\n",
    "optimizer = optim.Adam(params = model_lstm.parameters(), lr = LEARNING_RATE)\n",
    "loss_fn = nn.MSELoss()\n",
    "trainer = ModelTrainer(model_lstm, train_dataloader, val_dataloader, device, EPOCHS, ROUND_LOSS, ROUND_RMSE, optimizer, loss_fn)\n",
    "trainer.train(PATH_TO_MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Google Colab Analog 2024 (PyTorch 2.5.1 + TensorFlow 2.18) [python-google_colab_gpu_2024]",
   "language": "python",
   "name": "conda-env-python-google_colab_gpu_2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
