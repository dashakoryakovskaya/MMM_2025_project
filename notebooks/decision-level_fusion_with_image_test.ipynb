{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d093175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings(\"ignore\", category = warn)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233acfbc",
   "metadata": {},
   "source": [
    "#### Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31d3d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['activation_date'] = pd.to_datetime(df['activation_date'])\n",
    "\n",
    "    df['day'] = df['activation_date'].dt.day\n",
    "    df['month'] = df[\"activation_date\"].dt.month\n",
    "    df['year'] = df[\"activation_date\"].dt.year\n",
    "    df['weekday'] = df['activation_date'].dt.weekday\n",
    "    df[\"dayofyear\"] = df['activation_date'].dt.dayofyear\n",
    "    df.drop(columns=['activation_date', 'item_id'], inplace=True)\n",
    "    df['param_1'] = df['param_1'].fillna('')\n",
    "    df['param_2'] = df['param_2'].fillna('')\n",
    "    df['param_3'] = df['param_3'].fillna('')\n",
    "    df['description'] = df['description'].fillna('')\n",
    "    return df\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "item_id = test.item_id\n",
    "test = preprocess(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f13f4c",
   "metadata": {},
   "source": [
    "На табличных данных + тексте лучшие результаты получили RNN и Transformer соответственно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265a27c",
   "metadata": {},
   "source": [
    "### Табличные данные RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c71ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tabular = pd.read_csv(\"../results/rnn-tabular.csv\").deal_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3b2ab",
   "metadata": {},
   "source": [
    "### Текст Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efce2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_text = pd.read_csv(\"../results/transformer-text.csv\").deal_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c584f",
   "metadata": {},
   "source": [
    "### Изображения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff7b900",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b13a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer_2 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = F.gelu(x)  # Более плавная активация\n",
    "        x = self.dropout(x)\n",
    "        return self.layer_2(x)\n",
    "\n",
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        return self.norm(x + self.dropout(residual))\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(1)].detach()  # Отключаем градиенты\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dropout=0.1, positional_encoding=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.self_attention = nn.MultiheadAttention(input_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.feed_forward = PositionWiseFeedForward(input_dim, input_dim, dropout=dropout)\n",
    "        self.add_norm_after_attention = AddAndNorm(input_dim, dropout=dropout)\n",
    "        self.add_norm_after_ff = AddAndNorm(input_dim, dropout=dropout)\n",
    "        self.positional_encoding = PositionalEncoding(input_dim) if positional_encoding else None\n",
    "\n",
    "    def forward(self, key, value, query):\n",
    "        if self.positional_encoding:\n",
    "            key = self.positional_encoding(key)\n",
    "            value = self.positional_encoding(value)\n",
    "            query = self.positional_encoding(query)\n",
    "\n",
    "        attn_output, _ = self.self_attention(query, key, value, need_weights=False)\n",
    "\n",
    "        x = self.add_norm_after_attention(attn_output, query)\n",
    "\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.add_norm_after_ff(ff_output, x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baeed15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModelWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim = 1024, hidden_dim=128, num_heads = 4, num_layers = 8, dropout = 0.1, positional_encoding=True):\n",
    "        super(TransformerModelWithAttention, self).__init__()\n",
    "        self.in_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.positional_encoding = PositionalEncoding(hidden_dim)\n",
    "        self.transformer_encoder = nn.ModuleList([TransformerEncoderLayer(input_dim=hidden_dim, num_heads=num_heads, positional_encoding=positional_encoding, dropout=dropout) for i in range(num_layers)])\n",
    "        self.fc_out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = self.in_layer(x)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        x = self.positional_encoding(x)\n",
    "        for i in range(len(self.transformer_encoder)):\n",
    "            x = x + self.transformer_encoder[i](x, x, x)\n",
    "        x = x.mean(dim = 1)\n",
    "        return self.fc_out(x).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9e0799a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModelWithAttention(num_layers=2, input_dim=768, hidden_dim=128, num_heads=2)\n",
    "checkpoint = torch.load(\"models/TransformerModelWithAttention_4_0.91_checkpoint.pth\", map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b4ec44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64c696c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508438/508438 [02:52<00:00, 2949.60it/s]  \n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "len_test = test.shape[0]\n",
    "x = 200\n",
    "for i, row in tqdm(test.iterrows(), total=len_test):\n",
    "    if i == 32001:\n",
    "        x = 100\n",
    "    if i <= 36600 and i % 200 == 0:\n",
    "        with open(\"../data/vit/vit_test_jpg_\" + str(i-1+200), \"rb\") as f: \n",
    "            vit_emb = CPU_Unpickler(f).load() \n",
    "    if i > 36600 and i % 100 == 0:\n",
    "        try:\n",
    "            with open(\"../data/vit/vit_test_jpg_\" + str(i-1+100), \"rb\") as f: \n",
    "                vit_emb = CPU_Unpickler(f).load() \n",
    "        except:\n",
    "            vit_emb = [None] * 100\n",
    "    image_embedding = vit_emb[i % x]\n",
    "    if image_embedding is None:\n",
    "        y_pred.append(0.0)\n",
    "    else:\n",
    "        if image_embedding.shape[0] == 1:\n",
    "            y_pred.append(float(model(image_embedding.float())))\n",
    "        else:\n",
    "            y_pred.append(float(model(image_embedding.unsqueeze(0).float())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d8a4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_image = np.clip(y_pred, 0, 1)\n",
    "pd.DataFrame({'item_id': item_id, 'deal_probability': result_image}).to_csv(\"../results/transformer-image.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d8a2a",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3e848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size = 1024, hidden_size = 64, num_layers = 2, dropout = 0.1, bidirectional=True):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = dropout,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(2 * hidden_size, 1)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.lstm.bidirectional:\n",
    "            h0, c0 = torch.zeros(2 * self.num_layers, len(x), self.hidden_size).to(device), torch.zeros(2 * self.num_layers, len(x), self.hidden_size).to(device)\n",
    "        else:\n",
    "            h0, c0 = torch.zeros(self.num_layers, len(x), self.hidden_size).to(device), torch.zeros(self.num_layers, len(x), self.hidden_size).to(device)\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        if self.lstm.bidirectional:\n",
    "            out = torch.cat((hn[-2, :, :], hn[-1, :, :]), dim=1)\n",
    "        else:\n",
    "            out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4193602d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(input_size=768)\n",
    "checkpoint = torch.load(\"models/LSTM_1_0.91_checkpoint.pth\", map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3089a4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508438/508438 [11:08<00:00, 760.70it/s]   \n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "len_test = test.shape[0]\n",
    "x = 200\n",
    "for i, row in tqdm(test.iterrows(), total=len_test):\n",
    "    if i == 32001:\n",
    "        x = 100\n",
    "    if i <= 36600 and i % 200 == 0:\n",
    "        with open(\"../data/vit/vit_test_jpg_\" + str(i-1+200), \"rb\") as f: \n",
    "            vit_emb = CPU_Unpickler(f).load() \n",
    "    if i > 36600 and i % 100 == 0:\n",
    "        try:\n",
    "            with open(\"../data/vit/vit_test_jpg_\" + str(i-1+100), \"rb\") as f: \n",
    "                vit_emb = CPU_Unpickler(f).load() \n",
    "        except:\n",
    "            vit_emb = [None] * 100\n",
    "    image_embedding = vit_emb[i % x]\n",
    "    if image_embedding is None:\n",
    "        y_pred.append(0.0)\n",
    "    else:\n",
    "        if image_embedding.shape[0] == 1:\n",
    "            y_pred.append(float(model(image_embedding.float())))\n",
    "        else:\n",
    "            y_pred.append(float(model(image_embedding.unsqueeze(0).float())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df9fcaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_image = np.clip(y_pred, 0, 1)\n",
    "pd.DataFrame({'item_id': item_id, 'deal_probability': result_image}).to_csv(\"../results/LSTM-image.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5d644",
   "metadata": {},
   "source": [
    "### RNN + Transformer + Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e2bd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_image = pd.read_csv(\"../results/transformer-image.csv\").deal_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "220025c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'item_id': item_id, 'deal_probability': (result_tabular + result_text + result_image) / 3.0}).to_csv(\"../results/decision_rnn_transformer_transformer.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda4ab7",
   "metadata": {},
   "source": [
    "Результат: 0.25816"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4195315",
   "metadata": {},
   "source": [
    "### RNN + Transformer + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5055fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_image = pd.read_csv(\"../results/LSTM-image.csv\").deal_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8685c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'item_id': item_id, 'deal_probability': (result_tabular + result_text + result_image) / 3.0}).to_csv(\"../results/decision_rnn_transformer_lstm.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddad865",
   "metadata": {},
   "source": [
    "Результат: 0.25829"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
